# hydra config
hydra:
  run:
    dir: ${log_path} # the log path, used for log and checkpoint
  sweep:
    dir: logs/
    subdir: ${experiment}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweeper:
    params:
      model.fuse_method: pose_atn
      model.fusion_layers: 0, 1, 2, 3, 4, 5
      model.backbone: 3dcnn

loss:
  lr: 0.0001
  beta1: 0.5 # decapture
  beta2: 0.999 # decapture

  selection: ["cls", "attn_loss", "bg", "tmp"] # the loss selection for the total loss

  lambda_list: [0.25, 0.5, 0.75, 1.0] # the lambda list for the total loss
  w_bg: 0.2 # the weight of background class for the loss function, used for cross validation with different class number
  w_temp: 0.05 # the weight of temporal smoothness for the loss function, used for cross validation with different class number

paths:
  root_path: /workspace/data/multi_view_driver_action

  annotation_path: ${paths.root_path}/label
  index_mapping: ${paths.root_path}/index_mapping # training mapping path, this used for cross validation, with different class number.
  start_mid_end_path: ${paths.root_path}/split_mid_end/mini.json # æˆ‘ä»¬ä¸éœ€è¦æ¨å¯¼å·¦å³çš„frameï¼ŒæŒ‰ç…§è¿™é‡Œé¢çš„startå’Œmidæ¥è¿›è¡Œæ¨å¯¼

  video_path: /workspace/data/videos_split
  sam3d_results_path: /workspace/data/sam3d_body_results_right

data:
  num_workers: 12
  img_size: 224

  uniform_temporal_subsample_num: 8 # num frame from the clip duration, f or define one gait cycle, we need use whole frames.

  batch_size: 1 # load video number

  fold: 5 # the fold number of the cross validation

  magic_move: true              # æ˜¯å¦å¯ç”¨ magic_move
  magic_move_ratio: 0.1         # æ¯”ä¾‹ï¼ˆé»˜è®¤ 0.1 = 10%ï¼‰
  magic_move_seed: 0            # éšæœºç§å­ï¼ˆé»˜è®¤ 0ï¼‰

  # ğŸ”‘ å…³é”®å‚æ•°ï¼šåˆ†å—åŠ è½½
  # å¦‚æœvideoè¶…è¿‡è¿™ä¸ªå¸§æ•°ï¼Œä¼šè¢«è‡ªåŠ¨åˆ†æˆå¤šä¸ªchunks
  # æ¯æ¬¡åªåŠ è½½ä¸€ä¸ªchunkï¼Œé¿å…åŠ è½½OOM
  max_video_frames: 120 # æ¨èå€¼ï¼š500-2000
  
  # max_video_frames é€‰æ‹©æŒ‡å—ï¼š
  # - 224Ã—224 åˆ†è¾¨ç‡ï¼š500-1000
  # - 112Ã—112 åˆ†è¾¨ç‡ï¼š1000-2000  
  # - æ›´å¤§åˆ†è¾¨ç‡ï¼š300-500
  # åŸåˆ™ï¼šå°½é‡å¤§ï¼ˆå‡å°‘chunksæ•°é‡ï¼‰ï¼Œä½†ä¸è¦OOM

model:
  backbone: 3dcnn # choices=[3dcnn, transformer, mamba], help='the backbone of the model'
  model_class_num: 9 # the class num, left, right, up, down, left_up, left_down, right_up, right_down, front
  use_side_heads: True # whether to use side heads for intermediate supervision
  fusion_mode: logit_mean # logit_mean | prob_mean | feature_mean | feature_concat
  modality_fusion: concat # concat | mean (for rgb+kpt)
  fusion_feature_dim: 256
  
  transformer_dim: 256
  transformer_layers: 4
  transformer_heads: 4
  transformer_ff_dim: 1024
  transformer_dropout: 0.1
  mamba_dim: 256
  mamba_layers: 2
  mamba_dropout: 0.1

  fuse_method: mid # add, mul, concat, none, late, avg

  # TS-CVA hyperparameters (all optional, defaults are shown)
  ts_cva_shared_backbone: true          # Share backbone across views (recommended)
  ts_cva_use_view_embedding: true       # Add view embeddings for view distinction
  ts_cva_use_gated_aggregation: true    # Use learnable gating (vs. mean pooling)
  ts_cva_num_heads: 4                   # Number of attention heads
  ts_cva_temporal_dim: 512              # Hidden dimension for temporal modeling
  ts_cva_temporal_layers: 2             # Number of TCN layers

train:
  # Training config
  max_epochs: 50 # numer of epochs of training

  view: single # single or multi
  view_name: ['front'] # used for train view, choices=['front', 'left', 'right']

  gpu: 0 # choices=[0, 1], help='the gpu number whicht to train'

log_path: logs/train/${experiment}/${now:%Y-%m-%d}/${now:%H-%M-%S}
experiment: ${train.view}_${train.view_name}_${model.backbone}_fuse_method_${model.fuse_method} # the experiment name, used for log path


# ========================================
# Ablation Study Configurations
# ========================================

# Ablation 1: TS-CVA without gated aggregation (use mean pooling)
# ts_cva_use_gated_aggregation: false

# Ablation 2: TS-CVA without view embeddings
# ts_cva_use_view_embedding: false

# Ablation 3: TS-CVA with non-shared backbone
# ts_cva_shared_backbone: false

# Ablation 4: Different number of attention heads
# ts_cva_num_heads: 8

# Ablation 5: Baseline - Single view
# train:
#   view: single
#   view_name: ['front']  # or ['left'] or ['right']
