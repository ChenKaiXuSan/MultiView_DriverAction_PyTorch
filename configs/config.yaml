# hydra config
hydra:
  run:
    dir: ${log_path} # the log path, used for log and checkpoint
  sweep:
    dir: logs/
    subdir: ${experiment}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweeper:
    params:
      model.fuse_method: pose_atn
      model.fusion_layers: 0, 1, 2, 3, 4, 5
      model.backbone: 3dcnn

loss:
  lr: 0.0001
  beta1: 0.5 # decapture
  beta2: 0.999 # decapture

  selection: ["cls", "attn_loss", "bg", "tmp"] # the loss selection for the total loss

  lambda_list: [0.25, 0.5, 0.75, 1.0] # the lambda list for the total loss
  w_bg: 0.2 # the weight of background class for the loss function, used for cross validation with different class number
  w_temp: 0.05 # the weight of temporal smoothness for the loss function, used for cross validation with different class number

paths:
  root_path: /workspace/data/multi_view_driver_action

  annotation_path: ${paths.root_path}/label
  index_mapping: ${paths.root_path}/index_mapping # training mapping path, this used for cross validation, with different class number.
  start_mid_end_path: ${paths.root_path}/split_mid_end/mini.json # æˆ‘ä»¬ä¸éœ€è¦æ¨å¯¼å·¦å³çš„frameï¼ŒæŒ‰ç…§è¿™é‡Œé¢çš„startå’Œmidæ¥è¿›è¡Œæ¨å¯¼

  video_path: /workspace/data/videos_split
  sam3d_results_path: /workspace/data/sam3d_body_results_right

data:
  num_workers: 12
  img_size: 224

  uniform_temporal_subsample_num: 8 # num frame from the clip duration, f or define one gait cycle, we need use whole frames.

  batch_size: 1 # load video number

  fold: 5 # the fold number of the cross validation

  # æ§åˆ¶æ•°æ®åŠ è½½
  load_rgb: true   # åŠ è½½è§†é¢‘å¸§
  load_kpt: false  # ä¸åŠ è½½å…³é”®ç‚¹ï¼ˆèŠ‚çœå†…å­˜å’Œæ—¶é—´ï¼‰
  
  # ğŸ”‘ å…³é”®å‚æ•°ï¼šåˆ†å—åŠ è½½
  # å¦‚æœvideoè¶…è¿‡è¿™ä¸ªå¸§æ•°ï¼Œä¼šè¢«è‡ªåŠ¨åˆ†æˆå¤šä¸ªchunks
  # æ¯æ¬¡åªåŠ è½½ä¸€ä¸ªchunkï¼Œé¿å…åŠ è½½OOM
  max_video_frames: 500 # æ¨èå€¼ï¼š500-2000
  
  # max_video_frames é€‰æ‹©æŒ‡å—ï¼š
  # - 224Ã—224 åˆ†è¾¨ç‡ï¼š500-1000
  # - 112Ã—112 åˆ†è¾¨ç‡ï¼š1000-2000  
  # - æ›´å¤§åˆ†è¾¨ç‡ï¼š300-500
  # åŸåˆ™ï¼šå°½é‡å¤§ï¼ˆå‡å°‘chunksæ•°é‡ï¼‰ï¼Œä½†ä¸è¦OOM
  
  # ğŸš€ ä¼˜åŒ–å‚æ•°ï¼šå¹¶è¡ŒåŠ è½½
  # æ§åˆ¶å¤šè§†è§’å’Œå…³é”®ç‚¹å¹¶è¡ŒåŠ è½½çš„çº¿ç¨‹æ•°
  # å¢åŠ æ­¤å€¼å¯æå‡I/Oæ€§èƒ½ï¼ˆéœ€è¦å¿«é€Ÿå­˜å‚¨æ”¯æŒï¼‰
  num_io_threads: 3 # æ¨èå€¼ï¼š3-8
  
  # num_io_threads é€‰æ‹©æŒ‡å—ï¼š
  # - NVMe SSDï¼š6-8ï¼ˆé«˜é€Ÿå­˜å‚¨ï¼‰
  # - SATA SSDï¼š4-6ï¼ˆä¸­é€Ÿå­˜å‚¨ï¼‰
  # - HDDï¼š2-3ï¼ˆæ…¢é€Ÿå­˜å‚¨ï¼‰
  # åŸåˆ™ï¼šå¿«é€Ÿå­˜å‚¨å¯ä½¿ç”¨æ›´å¤šçº¿ç¨‹ï¼Œæ…¢é€Ÿå­˜å‚¨å‡å°‘çº¿ç¨‹é¿å…ç£ç›˜æŠ–åŠ¨

model:
  backbone: 3dcnn # choices=[3dcnn, transformer, mamba, stgcn], help='the backbone of the model'
  model_class_num: 9 # the class num, left, right, up, down, left_up, left_down, right_up, right_down, front
  use_side_heads: True # whether to use side heads for intermediate supervision
  input_type: rgb # rgb | kpt | rgb_kpt
  fusion_mode: logit_mean # logit_mean | prob_mean | feature_mean | feature_concat
  modality_fusion: concat # concat | mean (for rgb+kpt)
  fusion_feature_dim: 256
  stgcn_hidden_dim: 64
  stgcn_layers: 3
  stgcn_temporal_kernel: 3
  stgcn_dropout: 0.1
  stgcn_num_kpts: null
  transformer_dim: 256
  transformer_layers: 4
  transformer_heads: 4
  transformer_ff_dim: 1024
  transformer_dropout: 0.1
  mamba_dim: 256
  mamba_layers: 2
  mamba_dropout: 0.1

  fuse_method: late # add, mul, concat, none, late, avg, cross_atn, se_atn, pose_atn
  
  # ğŸ§  å†…å­˜ä¼˜åŒ–ï¼šæ¢¯åº¦æ£€æŸ¥ç‚¹ (Gradient Checkpointing)
  # å¯¹äºå¤§æ¨¡å‹ï¼Œå¯ä»¥ç”¨è®¡ç®—æ—¶é—´æ¢å†…å­˜ç©ºé—´
  # å»ºè®®ï¼šTransformer/Mambaæ¨¡å‹å¼€å¯ï¼Œ3DCNNå¯é€‰
  use_gradient_checkpointing: false

train:
  # Training config
  max_epochs: 50 # numer of epochs of training

  view: single # single or multi
  view_name: front # used when train.view=single
  feature_map_batches: 10 # dump CAM features for first N test batches

  gpu: 0 # choices=[0, 1], help='the gpu number whicht to train'
  
  # ğŸš€ å†…å­˜ä¼˜åŒ–ï¼šæ¢¯åº¦ç´¯ç§¯ (Gradient Accumulation)
  # ç”¨å¤šä¸ªå°batchæ¨¡æ‹Ÿå¤§batchè®­ç»ƒï¼Œæ˜¾è‘—é™ä½å†…å­˜ä½¿ç”¨
  # å®é™…batch_size Ã— accumulate_grad_batches = æœ‰æ•ˆbatch_size
  # å»ºè®®å€¼ï¼š2-8ï¼ˆæ ¹æ®GPUå†…å­˜è°ƒæ•´ï¼‰
  accumulate_grad_batches: 1  # 1è¡¨ç¤ºä¸ç´¯ç§¯ï¼ˆé»˜è®¤ï¼‰
  
  # ğŸ§¹ å†…å­˜æ¸…ç†ï¼šå¯ç”¨è‡ªåŠ¨åƒåœ¾å›æ”¶
  # åœ¨æ¯ä¸ªè®­ç»ƒæ­¥éª¤åæ¸…ç†æœªä½¿ç”¨çš„å†…å­˜
  enable_memory_cleanup: false  # å¯é€‰ï¼šæ˜¾å¼å†…å­˜æ¸…ç†ï¼ˆå¯èƒ½ç•¥å¾®é™ä½é€Ÿåº¦ï¼‰

# âš¡ Trainer é…ç½®ï¼ˆç”¨äºPyTorch Lightning Trainerï¼‰
trainer:
  # ğŸ”¥ æ··åˆç²¾åº¦è®­ç»ƒ (Mixed Precision Training)
  # ä½¿ç”¨FP16åŠç²¾åº¦è®­ç»ƒï¼Œå†…å­˜å‡åŠï¼Œé€Ÿåº¦æå‡30-50%
  # éœ€è¦æ”¯æŒçš„GPU: V100, A100, RTXç³»åˆ—, T4ç­‰
  # é€‰é¡¹ï¼š32 (FP32é»˜è®¤), 16 (FP16), 'bf16' (BFloat16ï¼ŒA100/H100æ¨è)
  precision: 32  # é»˜è®¤FP32ï¼Œæ”¹ä¸º16å¯ç”¨æ··åˆç²¾åº¦
  
  # æ¢¯åº¦ç´¯ç§¯é…ç½®ï¼ˆä¹Ÿå¯ä»¥åœ¨è¿™é‡Œè®¾ç½®ï¼Œä¼šè¦†ç›–train.accumulate_grad_batchesï¼‰
  # accumulate_grad_batches: 1

log_path: logs/train/${experiment}/${now:%Y-%m-%d}/${now:%H-%M-%S}
experiment: view_${train.view}_${train.view_name}_${model.backbone}_fuse_method_${model.fuse_method} # the experiment name, used for log path
