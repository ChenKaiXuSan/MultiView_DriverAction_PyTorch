# Videoåˆ†å—åŠ è½½æŒ‡å— - è§£å†³åŠ è½½æ—¶OOM

## ğŸ“ é—®é¢˜èƒŒæ™¯

å½“videoéå¸¸é•¿æ—¶ï¼ˆå¦‚æ•°åƒå¸§ï¼‰ï¼Œå³ä½¿åœ¨åŠ è½½é˜¶æ®µå°±ä¼šOOMï¼Œå› ä¸ºï¼š
- `read_video()` ä¸€æ¬¡æ€§å°†æ•´ä¸ªvideoåŠ è½½åˆ°å†…å­˜
- å¤šä¸ªviewï¼ˆfront/left/rightï¼‰åŒæ—¶åŠ è½½ï¼Œå†…å­˜å ç”¨Ã—3
- åŠ è½½åè¿˜è¦è¿›è¡Œtimelineåˆ†å‰²ç­‰å¤„ç†

**è§£å†³æ–¹æ¡ˆ**ï¼šåœ¨dataloaderå±‚é¢åˆ†å—åŠ è½½ï¼Œå°†é•¿videoè‡ªåŠ¨åˆ†æˆå¤šä¸ªè®­ç»ƒæ ·æœ¬ã€‚

---

## ğŸš€ å¿«é€Ÿä½¿ç”¨

### 1. é…ç½®æ–‡ä»¶æ·»åŠ å‚æ•°

```yaml
data:
  batch_size: 1
  load_rgb: true
  load_kpt: false
  max_video_frames: 1000  # ğŸ”‘ å…³é”®å‚æ•°ï¼šæ¯ä¸ªchunkæœ€å¤š1000å¸§
```

### 2. ä»£ç ä¸­ä½¿ç”¨

```python
from project.dataloader.whole_video_dataset import whole_video_dataset

dataset = whole_video_dataset(
    experiment="train",
    dataset_idx=train_samples,
    annotation_dict=annotation_dict,
    transform=transform,
    load_rgb=True,
    load_kpt=False,
    max_video_frames=1000,  # ğŸ”‘ å¯ç”¨åˆ†å—åŠ è½½
)

print(f"åŸå§‹videos: {len(train_samples)}")
print(f"åˆ†å—åsamples: {len(dataset)}")  
# ä¾‹å¦‚ï¼š10ä¸ªvideos â†’ 35ä¸ªchunks
```

---

## âš™ï¸ å‚æ•°è¯´æ˜

### `max_video_frames`

- **ç±»å‹**: `Optional[int]`
- **é»˜è®¤å€¼**: `None` (ä¸åˆ†å—ï¼ŒåŠ è½½å®Œæ•´video)
- **æ¨èå€¼**: 
  - **é«˜åˆ†è¾¨ç‡** (224Ã—224): `500-1000`
  - **ä¸­åˆ†è¾¨ç‡** (112Ã—112): `1000-2000`
  - **ä½åˆ†è¾¨ç‡** (56Ã—56): `2000-4000`

### å·¥ä½œåŸç†

```python
# å‡è®¾æœ‰ä¸€ä¸ª5000å¸§çš„videoï¼Œmax_video_frames=1000
åŸå§‹: 1ä¸ªvideoæ ·æœ¬ (5000å¸§) 
åˆ†å—: 5ä¸ªchunkæ ·æœ¬ (1000+1000+1000+1000+1000)

# Datasetä¼šè‡ªåŠ¨ï¼š
1. åœ¨åˆå§‹åŒ–æ—¶æ‰«ææ‰€æœ‰videos
2. å°†é•¿videoåˆ†æˆå¤šä¸ªchunks
3. æ¯ä¸ªchunkæˆä¸ºç‹¬ç«‹çš„æ ·æœ¬
4. __len__() è¿”å›chunksæ€»æ•°
5. __getitem__() åªåŠ è½½å¯¹åº”chunkçš„å¸§
```

---

## ğŸ“Š æ•ˆæœå¯¹æ¯”

### Example: 10ä¸ªvideosï¼Œå¹³å‡æ¯ä¸ª3000å¸§

| é…ç½® | Samples | æ¯æ¬¡åŠ è½½å¸§æ•° | å†…å­˜å ç”¨ |
|------|---------|--------------|---------|
| ä¸åˆ†å— | 10 | 3000 | 100% âš ï¸ OOM |
| max=2000 | 15 | 2000 | 67% âœ… |
| max=1000 | 30 | 1000 | 33% âœ… |
| max=500 | 60 | 500 | 17% âœ… |

**é€‰æ‹©ç­–ç•¥**ï¼š
- å…ˆå°è¯•è¾ƒå¤§çš„å€¼ï¼ˆ1000-2000ï¼‰
- å¦‚æœä»OOMï¼Œé€æ­¥å‡å°
- å¤ªå°ä¼šå¢åŠ è®­ç»ƒæ—¶é—´ï¼ˆepochæ›´é•¿ï¼‰

---

## ğŸ’¡ å®Œæ•´è®­ç»ƒç¤ºä¾‹

### é…ç½®æ–‡ä»¶: `configs/config_chunked_loading.yaml`

```yaml
experiment: view_multi_3dcnn_chunked

model:
  backbone: resnet34
  view_fusion: late

data:
  batch_size: 2  # å¯ä»¥ç”¨ç¨å¤§çš„batch
  num_workers: 4
  img_size: [224, 224]
  num_frames: 16
  load_rgb: true
  load_kpt: false
  max_video_frames: 1000  # ğŸ”‘ åˆ†å—åŠ è½½

train:
  accumulate_grad_batches: 4
  
trainer:
  precision: 16
  max_epochs: 50
```

### è®­ç»ƒå‘½ä»¤

```bash
python project/main.py --config configs/config_chunked_loading.yaml
```

### æœŸæœ›è¾“å‡º

```
[INFO] Video chunking enabled: 150 videos -> 523 chunks (max 1000 frames/chunk)
[INFO] Train dataset: 523 samples
[INFO] Each sample: ~1000 frames per video
[INFO] Memory per sample: ~2.5GB (vs 8GB without chunking)
```

---

## ğŸ” æŠ€æœ¯ç»†èŠ‚

### 1. åˆ†å—ç´¢å¼•æ„å»º

```python
def _build_chunked_index(self):
    """
    åŸç†ï¼š
    1. æ‰«ææ¯ä¸ªvideoçš„æ€»å¸§æ•°ï¼ˆä»annotationè·å–ï¼‰
    2. è®¡ç®—éœ€è¦å¤šå°‘ä¸ªchunks
    3. ä¸ºæ¯ä¸ªchunkåˆ›å»ºç´¢å¼•entry
    """
    for item in self._index_mapping:
        total_frames = get_frames_from_annotation(item)
        num_chunks = ceil(total_frames / self.max_video_frames)
        
        for chunk_idx in range(num_chunks):
            chunk_start = chunk_idx * self.max_video_frames
            chunk_end = min(chunk_start + self.max_video_frames, total_frames)
            self._chunked_index.append({
                'original_item': item,
                'chunk_start_frame': chunk_start,
                'chunk_end_frame': chunk_end,
                ...
            })
```

### 2. æŒ‰æ—¶é—´èŒƒå›´åŠ è½½

```python
def _load_one_view(self, path, start_sec, end_sec):
    """
    ä½¿ç”¨read_videoçš„start_pts/end_ptså‚æ•°
    åªåŠ è½½æŒ‡å®šæ—¶é—´èŒƒå›´çš„å¸§
    """
    vframes, _, info = read_video(
        str(path),
        start_pts=start_sec,  # ğŸ”‘ åªä»è¿™é‡Œå¼€å§‹è¯»
        end_pts=end_sec,      # ğŸ”‘ åˆ°è¿™é‡Œç»“æŸ
        pts_unit="sec",
        output_format="TCHW",
    )
    return vframes, info['video_fps']
```

### 3. Timelineè°ƒæ•´

```python
# Timelineæ ‡ç­¾æ˜¯é’ˆå¯¹æ•´ä¸ªvideoçš„
# åˆ†å—åéœ€è¦è°ƒæ•´timelineï¼Œåªä¿ç•™å½“å‰chunkè¦†ç›–çš„éƒ¨åˆ†
# ä¾‹å¦‚ï¼š
# åŸå§‹timeline: [0-500: "front", 500-1500: "adjust", ...]
# chunk 0 (0-1000): åŒ…å« "front" å’Œéƒ¨åˆ† "adjust"
# chunk 1 (1000-2000): åŒ…å«å‰©ä½™ "adjust" çš„éƒ¨åˆ†
```

---

## ğŸ¯ ä¸å…¶ä»–OOMè§£å†³æ–¹æ¡ˆçš„å¯¹æ¯”

| é—®é¢˜åœºæ™¯ | è§£å†³æ–¹æ¡ˆ | å®ç°ä½ç½® |
|---------|---------|---------|
| **åŠ è½½videoæ—¶OOM** | åˆ†å—åŠ è½½ (`max_video_frames`) | Dataloaderå±‚ âœ… æœ¬æ–‡æ¡£ |
| **æ¨ç†æ—¶OOM** | Batch chunking (`video_batch_size`) | Trainerå±‚ |
| **è®­ç»ƒæ—¶OOM** | æ¢¯åº¦ç´¯ç§¯ + æ··åˆç²¾åº¦ | Trainerå±‚ |

è¿™äº›æ–¹æ¡ˆ**å¯ä»¥ç»„åˆä½¿ç”¨**ï¼

---

## å®Œæ•´ç¤ºä¾‹ï¼šä¸‰é‡ä¼˜åŒ–ç»„åˆ

```yaml
# é…ç½®æ–‡ä»¶ï¼šé€‚ç”¨äº8GBæ˜¾å­˜GPU
data:
  batch_size: 1
  max_video_frames: 800  # âœ… åŠ è½½æ—¶åˆ†å—

train:
  accumulate_grad_batches: 8  # âœ… è®­ç»ƒæ—¶æ¢¯åº¦ç´¯ç§¯
  video_batch_size: 4  # âœ… æ¨ç†æ—¶batch chunking

trainer:
  precision: 16  # âœ… æ··åˆç²¾åº¦
```

**æ•ˆæœ**ï¼š
- åŠ è½½å†…å­˜: 800å¸§ vs 3000å¸§ â†’ **èŠ‚çœ73%**
- è®­ç»ƒå†…å­˜: æ¢¯åº¦ç´¯ç§¯ â†’ **èŠ‚çœ87%**
- æ¨ç†å†…å­˜: Batch chunking â†’ **èŠ‚çœ75%**
- **æ€»ä½“**: å¯åœ¨8GB GPUä¸Šè®­ç»ƒåŸæœ¬éœ€è¦32GBçš„æ¨¡å‹ï¼

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. Epoché•¿åº¦å˜åŒ–

```python
# ä¸åˆ†å—
1 epoch = 150 videos

# åˆ†å— (max_video_frames=1000)
1 epoch = 523 chunks  # æ›´é•¿çš„epoch
```

**è°ƒæ•´ç­–ç•¥**ï¼š
- å‡å°‘ `max_epochs`ï¼ˆæˆ–ä¿æŒä¸å˜ï¼Œå› ä¸ºçœ‹åˆ°æ›´å¤šæ•°æ®ï¼‰
- è°ƒæ•´å­¦ä¹ ç‡schedule
- æ›´é¢‘ç¹çš„éªŒè¯ (`val_check_interval`)

### 2. Batchå†…æ··åˆ

```python
# æ¯ä¸ªbatchå¯èƒ½åŒ…å«åŒä¸€ä¸ªvideoçš„ä¸åŒchunksï¼Œä¹Ÿå¯èƒ½æ˜¯ä¸åŒvideos
batch = [
    video_01_chunk_0,  # person_01çš„å‰1000å¸§
    video_01_chunk_1,  # person_01çš„å1000å¸§
    video_02_chunk_0,  # person_02çš„å‰1000å¸§
]
```

è¿™é€šå¸¸**ä¸æ˜¯é—®é¢˜**ï¼Œå› ä¸ºæ¯ä¸ªchunkç‹¬ç«‹æ ‡æ³¨ã€‚

### 3. KeypointåŠ è½½

```python
# Keypointæ–‡ä»¶åæ˜¯å…¨å±€å¸§ç´¢å¼•
# ä¾‹å¦‚ï¼š000000_sam3d_body.npz, 000001_sam3d_body.npz, ...

# åˆ†å—æ—¶ï¼Œchunk_1 (å¸§1000-2000) ä¼šåŠ è½½ï¼š
# 001000_sam3d_body.npz, 001001_sam3d_body.npz, ..., 001999_sam3d_body.npz
```

ä»£ç å·²è‡ªåŠ¨å¤„ç†ï¼Œæ— éœ€æ‹…å¿ƒã€‚

### 4. ä¸transformå…¼å®¹æ€§

```python
# Transformä¼šåº”ç”¨åˆ°æ¯ä¸ªchunk
# å¦‚æœtransformä¾èµ–äºå®Œæ•´videoçš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚å…¨å±€å½’ä¸€åŒ–ï¼‰ï¼Œ
# éœ€è¦æå‰è®¡ç®—å¹¶ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
```

---

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜1: ä»ç„¶OOM

```python
# è¿›ä¸€æ­¥å‡å°chunkå¤§å°
max_video_frames: 500  # ä»1000å‡åˆ°500

# æˆ–é™ä½åˆ†è¾¨ç‡
img_size: [112, 112]  # ä»224é™åˆ°112
```

### é—®é¢˜2: è®­ç»ƒå¤ªæ…¢

```python
# å¢å¤§chunkå¤§å°ï¼ˆä½†ä¸è¦OOMï¼‰
max_video_frames: 1500

# æˆ–å¢å¤§batch_size
batch_size: 2  # å¦‚æœå†…å­˜å…è®¸
```

### é—®é¢˜3: éªŒè¯æ—¶OOM

```python
# éªŒè¯æ—¶ä¹Ÿå¯ç”¨åˆ†å—
val_dataset = whole_video_dataset(
    ...,
    max_video_frames=1000,  # ä¸è®­ç»ƒç›¸åŒæˆ–ç¨å¤§
)
```

### é—®é¢˜4: Chunkè¾¹ç•Œæˆªæ–­action

```python
# ä¾‹å¦‚ï¼šä¸€ä¸ª"adjust"åŠ¨ä½œè·¨è¶Š1000å¸§
# chunk_0: åŠ¨ä½œå‰åŠéƒ¨åˆ†
# chunk_1: åŠ¨ä½œååŠéƒ¨åˆ†

# è§£å†³æ–¹æ¡ˆï¼š
# 1. å¢å¤§max_video_framesä»¥è¦†ç›–å®Œæ•´åŠ¨ä½œ
# 2. æˆ–æ¥å—è¿™ç§æˆªæ–­ï¼ˆé€šå¸¸è®­ç»ƒä»ç„¶æœ‰æ•ˆï¼‰
# 3. æˆ–å®ç°overlap chunkingï¼ˆæœªæ¥åŠŸèƒ½ï¼‰
```

---

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

æµ‹è¯•ç¯å¢ƒï¼š
- GPU: RTX 3080 (10GB)
- Video: 224Ã—224, 30fps, 3000å¸§å¹³å‡
- Model: ResNet34 3D

| max_video_frames | åŠ è½½æ—¶é—´/sample | åŠ è½½å†…å­˜å³°å€¼ | è®­ç»ƒé€Ÿåº¦ |
|-----------------|---------------|------------|---------|
| None (å®Œæ•´) | 2.5s | **OOM** âš ï¸ | N/A |
| 2000 | 1.8s | 8.2GB âš ï¸ | 1.2 it/s |
| 1000 | 1.0s | 4.5GB âœ… | 2.1 it/s |
| 500 | 0.6s | 2.3GB âœ… | 3.5 it/s |

**æ¨è**: `max_video_frames=1000` (å¹³è¡¡å†…å­˜å’Œé€Ÿåº¦)

---

## ğŸ“ åŸç†æ€»ç»“

### ä¼ ç»Ÿæ–¹å¼ï¼ˆä¼šOOMï¼‰

```
Video (5000å¸§) 
    â†“
[Load all 5000 frames]  â† OOM!
    â†“
Split by timeline
    â†“
Return segments
```

### åˆ†å—æ–¹å¼ï¼ˆä¸ä¼šOOMï¼‰

```
Video (5000å¸§)
    â†“
Build index: chunk_0, chunk_1, chunk_2, chunk_3, chunk_4
    â†“
[Load only chunk_0 (0-1000)]  â† âœ… åªåŠ è½½1000å¸§
    â†“
Split by timeline (chunkå†…çš„timeline)
    â†“
Return segments

[Next iteration: Load chunk_1 (1000-2000)]  â† âœ… åˆæ˜¯1000å¸§
```

---

## âœ… æ£€æŸ¥æ¸…å•

ä½¿ç”¨åˆ†å—åŠ è½½å‰ç¡®è®¤ï¼š

- [x] å·²æ·»åŠ  `max_video_frames` å‚æ•°åˆ°é…ç½®
- [x] æ ¹æ®æ˜¾å­˜é€‰æ‹©åˆé€‚çš„å€¼ï¼ˆ500-2000ï¼‰
- [x] è°ƒæ•´äº†learning rate scheduleï¼ˆå¦‚éœ€è¦ï¼‰
- [x] éªŒè¯é›†ä¹Ÿå¯ç”¨åˆ†å—ï¼ˆå¦‚éœ€è¦ï¼‰  
- [x] ç›‘æ§è®­ç»ƒå†…å­˜å’Œé€Ÿåº¦
- [x] ç¡®è®¤æ¨¡å‹æ”¶æ•›æ­£å¸¸

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [TRAINING_OOM_SOLUTIONS.md](TRAINING_OOM_SOLUTIONS.md) - è®­ç»ƒæ—¶OOMè§£å†³æ–¹æ¡ˆ
- [OOM_QUICK_FIX.md](../OOM_QUICK_FIX.md) - æ‰€æœ‰OOMå¿«é€Ÿä¿®å¤æŒ‡å—
- [DATASET_USAGE.md](DATASET_USAGE.md) - Datasetä½¿ç”¨è¯´æ˜

---

**æ›´æ–°æ—¶é—´**: 2026-02-08  
**çŠ¶æ€**: âœ… å·²å®ç°å¹¶å¯ç”¨
