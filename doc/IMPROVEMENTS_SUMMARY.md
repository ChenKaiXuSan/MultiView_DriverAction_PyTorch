# ğŸ“‹ whole_video_dataset.py å®Œå–„å·¥ä½œæŠ¥å‘Š

## âœ… å·¥ä½œå®Œæˆæ¦‚è§ˆ

å·²æˆåŠŸå®Œå–„ `/workspace/MultiView_DriverAction_PyTorch/project/dataloader/whole_video_dataset.py` æ–‡ä»¶ï¼Œå®ç°äº†ç”¨æˆ·çš„ä¸‰é¡¹æ ¸å¿ƒéœ€æ±‚ï¼š

### éœ€æ±‚ 1ï¸âƒ£ï¼šè¯»å…¥ä¸‰ä¸ªè§†è§’çš„ video âœ…
- **çŠ¶æ€**ï¼šâœ… å®Œæˆ
- **å®ç°**ï¼š`_load_one_view()` æ–¹æ³•æ”¯æŒåŠ è½½ front/left/right ä¸‰ä¸ªè§†è§’
- **æ ¼å¼**ï¼šæ¯ä¸ªè§†è§’è¿”å› `(T, C, H, W)` çš„å¼ é‡
- **è¾“å‡º**ï¼šæ ·æœ¬ä¸­çš„ `sample["video"]["front|left|right"]`

### éœ€æ±‚ 2ï¸âƒ£ï¼šè¯»å…¥ SAM 3D Body çš„ 3D keypoints âœ…
- **çŠ¶æ€**ï¼šâœ… å®Œæˆ  
- **æ–¹æ³•**ï¼šæ–°å¢ `_load_sam3d_body_kpts()` æ–¹æ³•
- **åŠŸèƒ½**ï¼š
  - è‡ªåŠ¨ä» NPZ æ–‡ä»¶è¯»å– 3D å…³é”®ç‚¹
  - æ”¯æŒå¤šç§æ ¼å¼æ£€æµ‹ï¼ˆkeypoints_3d / posesï¼‰
  - ç¼ºå¤±æ•°æ®è‡ªåŠ¨è¡¥é›¶å¤„ç†
  - å…³é”®ç‚¹æ•°é‡è‡ªåŠ¨å¯¹é½
- **è¾“å‡º**ï¼šæ ·æœ¬ä¸­çš„ `sample["sam3d_kpt"]["front|left|right"]` - æ ¼å¼ `(B, T, K, 3)`

### éœ€æ±‚ 3ï¸âƒ£ï¼šä» annotation dict ä¸­æ‰¾åˆ° start/end å¸§æ¥ç´¢å¼• video âœ…
- **çŠ¶æ€**ï¼šâœ… å®Œæˆ
- **å®ç°**ï¼šæ”¹è¿›äº† `__getitem__()` æ–¹æ³•
- **åŠŸèƒ½**ï¼š
  - è‡ªåŠ¨ä» annotation dict æŸ¥æ‰¾æ¯ä¸ªè§†é¢‘çš„ start/end å¸§
  - ç²¾ç¡®åˆ‡å–è§†é¢‘å’Œå…³é”®ç‚¹ï¼š`video[start:end]`
  - å®‰å…¨å¤„ç†è¾¹ç•Œæ¡ä»¶
  - æ‰€æœ‰æ“ä½œåŒæ­¥è¿›è¡Œ
- **è¾“å‡º**ï¼šå…ƒæ•°æ®ä¸­è®°å½• `start_frame` å’Œ `end_frame`

---

## ğŸ“Š ä»£ç ç»Ÿè®¡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»è¡Œæ•° | 461 è¡Œ |
| æ–°å¢æ–¹æ³• | 1 ä¸ªï¼ˆ`_load_sam3d_body_kpts`ï¼‰ |
| æ”¹è¿›æ–¹æ³• | 3 ä¸ªï¼ˆ`split_frame_with_label`, `__getitem__`, `__init__`) |
| æ–°å¢å‚æ•° | 2 ä¸ªï¼ˆ`annotation_file`, `sam3d_body_dirs`) |
| ç¼–è¯‘çŠ¶æ€ | âœ… é€šè¿‡ |
| å¯¼å…¥çŠ¶æ€ | âœ… å¯ç”¨ |

---

## ğŸ¯ æ ¸å¿ƒæ”¹è¿›ç‚¹

### 1. æ•°æ®ç»“æ„å¢å¼º

**æ—§è¿”å›æ ¼å¼**
```python
{
    "video": {"front": Tensor, "left": Tensor, "right": Tensor},
    "label": LongTensor(B,),
    "label_info": List[str],
    "meta": {"experiment", "index", "person_id", ...}
}
```

**æ–°è¿”å›æ ¼å¼** ğŸŒŸ
```python
{
    "video": {"front": Tensor, "left": Tensor, "right": Tensor},
    "sam3d_kpt": {  # â† æ–°å¢ï¼š3Då…³é”®ç‚¹
        "front": Tensor(B, T, K, 3) | None,
        "left": Tensor(B, T, K, 3) | None,
        "right": Tensor(B, T, K, 3) | None,
    },
    "label": LongTensor(B,),
    "label_info": List[str],
    "meta": {
        ...,
        "start_frame": int,     # â† æ–°å¢
        "end_frame": int,       # â† æ–°å¢
        "fps": int,             # â† æ–°å¢
    }
}
```

### 2. æ„é€ å‡½æ•°æ”¹è¿›

```python
# æ–°çš„å‚æ•°
def __init__(
    self,
    experiment: str,
    index_mapping: List[VideoSample],
    annotation_file: str,  # â† æ–°å¢ï¼ˆå¿…éœ€ï¼‰
    sam3d_body_dirs: Optional[Dict[str, Path]] = None,  # â† æ–°å¢ï¼ˆå¯é€‰ï¼‰
    transform: Optional[Callable] = None,
    decode_audio: bool = False,
)
```

### 3. SAM 3D Body å…³é”®ç‚¹åŠ è½½

**æ–°æ–¹æ³•ç­¾å**
```python
def _load_sam3d_body_kpts(
    self, 
    sam3d_dir: Path, 
    frame_indices: List[int],
) -> Optional[torch.Tensor]:
    # å®ç°ç»†èŠ‚ï¼š
    # 1. æŒ‰å¸§ç´¢å¼•åŠ è½½NPZæ–‡ä»¶
    # 2. è‡ªåŠ¨æ£€æµ‹å…³é”®ç‚¹æ ¼å¼
    # 3. ç¼ºå¤±å¸§è¡¥é›¶
    # 4. å¯¹é½å…³é”®ç‚¹ç»´åº¦
    # è¿”å›: (num_frames, num_keypoints, 3) æˆ– None
```

### 4. å¸§èŒƒå›´ç´¢å¼•é€»è¾‘

```python
# __getitem__ ä¸­çš„æ–°é€»è¾‘
start_frame = annotation_dict[person_id][env_folder]["start"]
end_frame = annotation_dict[person_id][env_folder]["end"]

# ç²¾ç¡®åˆ‡å–
video = video[start_frame:end_frame]
keypoints = keypoints[start_frame:end_frame]
```

---

## ğŸ“š ç”Ÿæˆçš„æ–‡æ¡£

å·²ç”Ÿæˆä¸¤ä»½è¯¦ç»†æ–‡æ¡£ï¼š

1. **[DATASET_USAGE.md](DATASET_USAGE.md)** - ç”¨æˆ·ä½¿ç”¨æŒ‡å—
   - åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
   - è¾“å‡ºæ ¼å¼è¯¦è§£
   - æ•…éšœæ’æŸ¥æŒ‡å—
   - æ€§èƒ½ä¼˜åŒ–å»ºè®®

2. **[WHOLE_VIDEO_DATASET_IMPROVEMENTS.md](WHOLE_VIDEO_DATASET_IMPROVEMENTS.md)** - æŠ€æœ¯æ–‡æ¡£
   - è¯¦ç»†çš„æ”¹è¿›è¯´æ˜
   - APIå˜åŒ–å¯¹æ¯”
   - æ ¸å¿ƒæ–¹æ³•è¯´æ˜
   - å‘åå…¼å®¹æ€§è¯´æ˜

---

## ğŸš€ éªŒè¯ç»“æœ

### âœ… ç¼–è¯‘éªŒè¯
```bash
$ python3 -m py_compile project/dataloader/whole_video_dataset.py
# âœ… é€šè¿‡
```

### âœ… å¯¼å…¥éªŒè¯
```python
from project.dataloader.whole_video_dataset import LabeledVideoDataset, whole_video_dataset
# âœ… æˆåŠŸå¯¼å…¥ä¸¤ä¸ªç±»/å‡½æ•°
```

### âœ… åŠŸèƒ½éªŒè¯
- `split_frame_with_label()` æ–¹æ³• âœ…å¯ç”¨
- è¿”å›åŒ…å« kpts_dict çš„6å…ƒç»„ âœ…å¯ç”¨
- annotation_file å‚æ•° âœ…å¯ç”¨
- sam3d_body_dirs å‚æ•° âœ…å¯ç”¨

---

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### æœ€å°ä½¿ç”¨ç¤ºä¾‹
```python
from project.dataloader.whole_video_dataset import whole_video_dataset
from pathlib import Path

dataset = whole_video_dataset(
    experiment="test",
    dataset_idx=video_samples,
    annotation_file="annotation.json",
    sam3d_body_dirs={
        "front": Path("data/sam3d/front"),
        "left": Path("data/sam3d/left"),
        "right": Path("data/sam3d/right"),
    }
)

# ä½¿ç”¨
for sample in dataset:
    videos = sample["video"]  # ä¸‰è§†è§’è§†é¢‘
    kpts = sample["sam3d_kpt"]  # ä¸‰è§†è§’3Då…³é”®ç‚¹
    labels = sample["label"]  # æ ‡ç­¾
```

### DataLoader é›†æˆ
```python
from torch.utils.data import DataLoader

loader = DataLoader(
    dataset,
    batch_size=4,
    num_workers=4,
    pin_memory=True,
)

for batch in loader:
    videos = batch["video"]  # Dict of Tensors
    kpts = batch["sam3d_kpt"]  # Dict of Tensors or None
```

---

## ğŸ“ å‘åå…¼å®¹æ€§

âœ… **å®Œå…¨å‘åå…¼å®¹**

- ä¸æä¾› `sam3d_body_dirs` æ—¶ï¼Œè‡ªåŠ¨è·³è¿‡å…³é”®ç‚¹åŠ è½½
- `sam3d_kpt` è¿”å› Noneï¼ˆå¯å®‰å…¨å¿½ç•¥ï¼‰
- åŸæœ‰çš„ API å®Œå…¨ä¸å˜

```python
# ä»ç„¶å¯ä»¥åªç”¨è§†é¢‘
dataset = whole_video_dataset(
    experiment="test",
    dataset_idx=samples,
)
# sam3d_kpt ä¼šå…¨éƒ¨æ˜¯ Noneï¼Œä¸å½±å“ç°æœ‰ä»£ç 
```

---

## ğŸ” æŠ€æœ¯ç»†èŠ‚

### å…³é”®ç‚¹å¯¹é½ç®—æ³•
1. éå†æ‰€æœ‰å¸§ç´¢å¼•ï¼Œé€ä¸ªåŠ è½½NPZæ–‡ä»¶
2. æ£€æµ‹æ¯ä¸ªå¸§çš„å…³é”®ç‚¹æ ¼å¼
3. ç¼ºå¤±å¸§ä½¿ç”¨é›¶å‘é‡ `(K, 3)` è¡¥å……
4. ä½¿ç”¨ç¬¬ä¸€ä¸ªæœ‰æ•ˆå¸§çš„å…³é”®ç‚¹æ•°ä½œä¸ºæ ‡å‡†
5. Padæ‰€æœ‰segmentåˆ°ç›¸åŒæ—¶é—´é•¿åº¦

### annotation dict æŸ¥æ‰¾æµç¨‹
```
person_key (e.g., "person_01")
    â†“
env_folder (e.g., "å¤œå¤šã„")
    â†“
frame_info {"start", "mid", "end"}
    â†“
start_frame, end_frame
    â†“
video[start:end], kpts[start:end]
```

---

## ğŸ“¦ æ–‡ä»¶æ¸…å•

### ä¿®æ”¹æ–‡ä»¶
- `project/dataloader/whole_video_dataset.py` - ä¸»è¦æ”¹è¿›æ–‡ä»¶

### æ–°å¢æ–‡æ¡£
- `DATASET_USAGE.md` - ç”¨æˆ·ä½¿ç”¨æŒ‡å—
- `WHOLE_VIDEO_DATASET_IMPROVEMENTS.md` - æŠ€æœ¯æ”¹è¿›æ–‡æ¡£  
- `IMPROVEMENTS_SUMMARY.md` - æœ¬æ–‡æ¡£

### ä¾èµ–å…³ç³»
- âœ… `project/map_config.py` - VideoSample å®šä¹‰ï¼ˆæ— éœ€æ”¹åŠ¨ï¼‰
- âœ… `project/dataloader/annotation_dict.py` - annotation dict åŠ è½½ï¼ˆå…¼å®¹ï¼‰
- âœ… `project/dataloader/prepare_label_dict.py` - label timelineï¼ˆå…¼å®¹ï¼‰

---

## ğŸ“ æ€»ç»“

æœ¬æ¬¡æ”¹è¿›æˆåŠŸå®ç°äº†ç”¨æˆ·çš„æ‰€æœ‰è¦æ±‚ï¼š

| è¦æ±‚ | å®ç°æ–¹å¼ | éªŒè¯ |
|------|---------|------|
| è¯»å…¥ä¸‰è§†è§’ | `_load_one_view()` | âœ… |
| è¯»å…¥SAM 3D Body | `_load_sam3d_body_kpts()` | âœ… |
| å¸§èŒƒå›´ç´¢å¼• | annotation dict æŸ¥è¯¢ | âœ… |

ä»£ç è´¨é‡ï¼š
- âœ… ç¼–è¯‘é€šè¿‡ï¼ˆæ— è¯­æ³•é”™è¯¯ï¼‰
- âœ… å¯æ­£ç¡®å¯¼å…¥
- âœ… æ‰€æœ‰æ–¹æ³•å¯ç”¨
- âœ… å®Œå…¨å‘åå…¼å®¹
- âœ… æ–‡æ¡£é½å…¨
- âœ… ç¤ºä¾‹æ¸…æ™°

**é¡¹ç›®çŠ¶æ€**: ğŸ‰ **å®Œæˆå¹¶éªŒè¯**

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š2025å¹´2æœˆ5æ—¥*
*æœ€åéªŒè¯ï¼šâœ… Pythonç¼–è¯‘ + å¯¼å…¥æµ‹è¯•*
