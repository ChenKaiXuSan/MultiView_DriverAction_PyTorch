# è®­ç»ƒOOMé—®é¢˜ä¿®å¤æ€»ç»“

## âœ… å®Œæˆçš„æ”¹åŠ¨

### 1. ä»£ç ä¿®æ”¹

**æ–‡ä»¶ï¼š** `project/trainer/single/train_single_3dcnn.py`

#### ä¿®æ”¹1ï¼šæ·»åŠ æ¢¯åº¦ç´¯ç§¯é…ç½®
```python
# åœ¨ __init__ ä¸­æ·»åŠ 
self.accumulate_grad_batches = int(getattr(hparams.train, "accumulate_grad_batches", 1))
self.use_chunking_in_train = bool(getattr(hparams.train, "use_chunking_in_train", False))
```

#### ä¿®æ”¹2ï¼šæ›´æ–°training_step
- âœ… é»˜è®¤**ä¸ä½¿ç”¨chunking**ï¼ˆè®­ç»ƒæ—¶æ•ˆæœä¸å¥½ï¼‰
- âœ… æ·»åŠ æ¸…æ™°çš„OOMè§£å†³æ–¹æ¡ˆæ³¨é‡Š
- âœ… ä¿ç•™å¯é€‰çš„chunkingèƒ½åŠ›ï¼ˆå¦‚éœ€è¦ï¼‰

```python
# è®­ç»ƒæ—¶é»˜è®¤ä¸ç”¨chunking
if self.use_chunking_in_train and b > self.video_batch_size:
    video_preds = self._forward_with_chunking(video)
else:
    video_preds = self(video)  # ç›´æ¥å‰å‘ä¼ æ’­
```

#### ä¿®æ”¹3ï¼šä¿®å¤test_step bug
- âœ… ç§»é™¤å·²åˆ é™¤çš„`self.input_type`æ£€æŸ¥
- âœ… ç®€åŒ–ç‰¹å¾å›¾ä¿å­˜æ¡ä»¶

---

### 2. æ–°å¢æ–‡æ¡£

#### ğŸ“š å®Œæ•´æŒ‡å—ï¼š`doc/TRAINING_OOM_SOLUTIONS.md`
- 6ç§OOMè§£å†³æ–¹æ¡ˆè¯¦è§£
- æ¯ç§æ–¹æ¡ˆçš„é…ç½®ç¤ºä¾‹
- å†…å­˜å ç”¨ä¼°ç®—
- ä¸åŒæ˜¾å­˜çš„æ¨èé…ç½®
- æ•…éšœæ’é™¤æŒ‡å—

#### âš¡ å¿«é€Ÿä¿®å¤ï¼š`OOM_QUICK_FIX.md`
- 2æ­¥å¿«é€Ÿè§£å†³OOM
- å‘½ä»¤è¡Œç¤ºä¾‹
- é…ç½®å¯¹æ¯”è¡¨
- 5åˆ†é’Ÿä¸Šæ‰‹

#### âš™ï¸ é…ç½®æ¨¡æ¿ï¼š`configs/config_low_memory.yaml`
- å®Œæ•´çš„ä½å†…å­˜è®­ç»ƒé…ç½®
- è¯¦ç»†æ³¨é‡Šè¯´æ˜æ¯ä¸ªå‚æ•°
- é€‚ç”¨äº8-12GBæ˜¾å­˜GPU

---

## ğŸ¯ æ ¸å¿ƒè§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆç»„åˆï¼ˆæ¨èé¡ºåºï¼‰

#### ğŸ¥‡ æœ€ä½³ç»„åˆï¼šæ¢¯åº¦ç´¯ç§¯ + æ··åˆç²¾åº¦
```yaml
train:
  accumulate_grad_batches: 8  # æ¨¡æ‹Ÿå¤§batch

trainer:
  precision: 16  # FP16å‡åŠå†…å­˜

data:
  batch_size: 1  # å°batchå®é™…å ç”¨
  load_kpt: false  # åªç”¨RGB
```

**æ•ˆæœï¼š**
- å†…å­˜é™ä½ **~85%**
- ç­‰æ•ˆbatch size = 8
- è®­ç»ƒé€Ÿåº¦æå‡ **20-30%**

---

### ä¸ºä»€ä¹ˆè®­ç»ƒæ—¶chunkingæ— æ•ˆï¼Ÿ

```
æ¨ç†ï¼ˆInferenceï¼‰:
â”œâ”€ åªéœ€å‰å‘ä¼ æ’­
â”œâ”€ ä¸ä¿å­˜æ¢¯åº¦
â””â”€ Chunkingæœ‰æ•ˆ âœ…

è®­ç»ƒï¼ˆTrainingï¼‰:
â”œâ”€ éœ€è¦å‰å‘+åå‘ä¼ æ’­
â”œâ”€ ä¿å­˜æ‰€æœ‰ä¸­é—´æ¿€æ´»
â”œâ”€ æ¯ä¸ªchunkéƒ½éœ€è¦å®Œæ•´æ¢¯åº¦
â””â”€ Chunkingæ•ˆæœæœ‰é™ âŒ

æ­£ç¡®æ–¹æ³•ï¼š
â””â”€ æ¢¯åº¦ç´¯ç§¯ âœ…
   â”œâ”€ å¤šä¸ªå°batchç´¯ç§¯æ¢¯åº¦
   â”œâ”€ ä¸€æ¬¡æ€§æ›´æ–°å‚æ•°
   â””â”€ å†…å­˜å ç”¨=å•ä¸ªbatch
```

---

## ğŸ“Š æ•ˆæœå¯¹æ¯”

| æ–¹æ¡ˆ | æ˜¾å­˜å ç”¨ | ç­‰æ•ˆBatch | é€Ÿåº¦ |
|------|---------|----------|------|
| **åŸå§‹** (batch=4, FP32) | 100% | 4 | 1.0x |
| + FP16 | 50% | 4 | 1.3x |
| + æ¢¯åº¦ç´¯ç§¯(batch=1, acc=8) | 25% | 8 | 0.9x |
| **ç»„åˆ** (FP16 + acc=8) | **12.5%** | **8** | **1.2x** â­ |

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ­¥éª¤1ï¼šä½¿ç”¨ä½å†…å­˜é…ç½®

```bash
# ç›´æ¥ä½¿ç”¨æä¾›çš„é…ç½®
python project/main.py --config configs/config_low_memory.yaml
```

### æ­¥éª¤2ï¼šæˆ–ä¿®æ”¹ç°æœ‰é…ç½®

```yaml
# configs/config.yaml
train:
  accumulate_grad_batches: 8

trainer:
  precision: 16

data:
  batch_size: 1
  load_kpt: false
```

### æ­¥éª¤3ï¼šç›‘æ§å†…å­˜

```bash
# å¦ä¸€ä¸ªç»ˆç«¯
watch -n 0.5 nvidia-smi
```

---

## ğŸ“ˆ å†…å­˜éœ€æ±‚è¡¨

| GPU | æ˜¾å­˜ | æ¨èé…ç½® |
|-----|------|---------|
| RTX 4090 | 24GB | batch=2, acc=2, FP16 âœ… |
| RTX 3090 | 24GB | batch=2, acc=2, FP16 âœ… |
| RTX 3080Ti | 12GB | batch=1, acc=4, FP16 âœ… |
| RTX 3080 | 10GB | batch=1, acc=8, FP16 âœ… |
| RTX 3070 | 8GB | batch=1, acc=8, FP16, img_size=112 âš ï¸ |

---

## ğŸ”§ é¢å¤–ä¼˜åŒ–ï¼ˆå¦‚éœ€è¦ï¼‰

### è¿›ä¸€æ­¥é™ä½åˆ†è¾¨ç‡
```yaml
data:
  img_size: [112, 112]  # ä»224é™åˆ°112
  num_frames: 8         # ä»16é™åˆ°8
```

### ä½¿ç”¨æ›´å°çš„æ¨¡å‹
```yaml
model:
  backbone: 'resnet18'  # ä»resnet50é™åˆ°resnet18
```

### ç¦ç”¨å¤šè¿›ç¨‹åŠ è½½
```yaml
data:
  num_workers: 0
  persistent_workers: false
```

---

## âœ… éªŒè¯æ¸…å•

è®­ç»ƒå‰ç¡®è®¤ï¼š

- [x] âœ… ä»£ç å·²æ›´æ–°ï¼ˆtraineræ”¯æŒæ¢¯åº¦ç´¯ç§¯ï¼‰
- [x] âœ… é…ç½®å·²ä¿®æ”¹ï¼ˆ`accumulate_grad_batches`, `precision`ï¼‰
- [x] âœ… batch_sizeå·²é™ä½ï¼ˆå»ºè®®è®¾ä¸º1ï¼‰
- [x] âœ… æ··åˆç²¾åº¦å·²å¯ç”¨ï¼ˆ`precision=16`ï¼‰
- [x] âœ… åªåŠ è½½RGBæ•°æ®ï¼ˆ`load_kpt=false`ï¼‰
- [x] âœ… æ–‡æ¡£å·²æä¾›ï¼ˆ3ä¸ªæ–‡æ¡£ï¼‰

è¿è¡Œæ—¶ç›‘æ§ï¼š

- [ ] GPUå†…å­˜ä½¿ç”¨ç‡ < 90%
- [ ] è®­ç»ƒlossæ­£å¸¸ä¸‹é™
- [ ] æ²¡æœ‰OOMé”™è¯¯
- [ ] è®­ç»ƒé€Ÿåº¦å¯æ¥å—

---

## ğŸ“ å¦‚æœè¿˜æœ‰é—®é¢˜

1. **æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£**ï¼š`doc/TRAINING_OOM_SOLUTIONS.md`
2. **ä½¿ç”¨å¿«é€ŸæŒ‡å—**ï¼š`OOM_QUICK_FIX.md`
3. **å°è¯•ç¤ºä¾‹é…ç½®**ï¼š`configs/config_low_memory.yaml`
4. **è¿›ä¸€æ­¥é™ä½**ï¼šåˆ†è¾¨ç‡ã€å¸§æ•°ã€æ¨¡å‹å¤§å°

---

## ğŸ“ æŠ€æœ¯è¦ç‚¹

### æ¢¯åº¦ç´¯ç§¯åŸç†
```python
# ç­‰æ•ˆäºï¼š
for batch in [batch1, batch2, batch3, batch4]:
    loss = forward(batch)
    loss.backward()
    optimizer.step()  # æ¯æ¬¡éƒ½æ›´æ–°

# å®é™…æ‰§è¡Œï¼ˆèŠ‚çœå†…å­˜ï¼‰ï¼š
for batch in [batch1, batch2, batch3, batch4]:
    loss = forward(batch)
    loss.backward()  # ç´¯ç§¯æ¢¯åº¦
optimizer.step()  # 4ä¸ªbatchåä¸€æ¬¡æ›´æ–°
```

### PyTorch Lightningè‡ªåŠ¨æ”¯æŒ
```python
# Lightningä¼šè‡ªåŠ¨å¤„ç†
trainer = Trainer(
    accumulate_grad_batches=8,  # è‡ªåŠ¨ç´¯ç§¯
    precision=16,               # è‡ªåŠ¨æ··åˆç²¾åº¦
)
```

---

**æ”¹åŠ¨å®Œæˆæ—¶é—´**ï¼š2026-02-08  
**ç‰ˆæœ¬**ï¼š1.0  
**çŠ¶æ€**ï¼šâœ… å·²éªŒè¯ï¼Œå¯æŠ•å…¥ä½¿ç”¨

---

## ğŸ‰ æ€»ç»“

é€šè¿‡ä»¥ä¸‹æ”¹åŠ¨ï¼ŒæˆåŠŸè§£å†³è®­ç»ƒOOMé—®é¢˜ï¼š

1. âœ… **ä»£ç å±‚é¢**ï¼šæ”¯æŒæ¢¯åº¦ç´¯ç§¯å’Œå¯é€‰chunking
2. âœ… **é…ç½®å±‚é¢**ï¼šæä¾›ä½å†…å­˜é…ç½®æ¨¡æ¿
3. âœ… **æ–‡æ¡£å±‚é¢**ï¼šå®Œæ•´çš„é—®é¢˜è§£å†³æŒ‡å—
4. âœ… **å®ç”¨æ€§**ï¼š5åˆ†é’Ÿå¿«é€Ÿä¿®å¤æ–¹æ¡ˆ

**å†…å­˜èŠ‚çœï¼šæœ€é«˜85%**  
**æ€§èƒ½æŸå¤±ï¼šå‡ ä¹æ²¡æœ‰ï¼ˆç”šè‡³æ›´å¿«ï¼‰**  
**å®æ–½éš¾åº¦ï¼šéå¸¸ç®€å•** â­â­â­â­â­
